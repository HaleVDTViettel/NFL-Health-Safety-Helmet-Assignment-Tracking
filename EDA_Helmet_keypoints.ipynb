{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting a frame from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_from_video(frame, video):\n",
    "    frame = frame - 1\n",
    "    !ffmpeg \\\n",
    "        -hide_banner \\\n",
    "        -loglevel fatal \\\n",
    "        -nostats \\\n",
    "        -i $video -vf \"select=eq(n\\,$frame)\" -vframes 1 frame.png\n",
    "    img = Image.open('frame.png')\n",
    "    os.remove('frame.png')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'data/train/57583_000082_Endzone.mp4'\n",
    "frame = 1\n",
    "img = get_frame_from_video(frame, video)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint overlaying\n",
    "Annotate the image with the key-point information:\n",
    "- Calculate the x-y coordinate of the helmet's center. (For now, I will use the baseline bounding boxes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_df = pd.read_csv('data/train_baseline_helmets.csv')\n",
    "video_frame = Path(video).stem + '_' + str(frame)\n",
    "df = bboxes_df[bboxes_df['video_frame'] == video_frame].copy()\n",
    "xc = (df['left'] + df['width']/2).astype(int).values\n",
    "yc = (df['top'] + df['height']/2).astype(int).values\n",
    "xc, yc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame(img, xc, yc, r, col = (57, 255, 20)):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for x, y in zip(xc, yc):\n",
    "#         draw.point((x, y), fill=col)\n",
    "        draw.ellipse((x-r, y-r, x+r, y+r), fill=col, outline = 'black')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_frame(img, xc, yc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from: https://www.kaggle.com/robikscube/nfl-helmet-assignment-getting-started-guide\n",
    "def add_track_features(tracks, fps=59.94, snap_frame=10):\n",
    "    \"\"\"\n",
    "    Add column features helpful for syncing with video data.\n",
    "    \"\"\"\n",
    "    tracks = tracks.copy()\n",
    "    tracks[\"game_play\"] = (\n",
    "        tracks[\"gameKey\"].astype(\"str\")\n",
    "        + \"_\"\n",
    "        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n",
    "    )\n",
    "    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n",
    "    snap_dict = (\n",
    "        tracks.query('event == \"ball_snap\"')\n",
    "        .groupby(\"game_play\")[\"time\"]\n",
    "        .first()\n",
    "        .to_dict()\n",
    "    )\n",
    "    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n",
    "    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n",
    "    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n",
    "    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n",
    "        \"timedelta64[ms]\"\n",
    "    ) / 1_000\n",
    "    # Estimated video frame\n",
    "    tracks[\"est_frame\"] = (\n",
    "        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n",
    "    )\n",
    "    return tracks\n",
    "\n",
    "def add_video_features(videos):\n",
    "    videos['game_play'] = videos['video_frame'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "    videos['camera'] = videos['video_frame'].apply(lambda x: x.split('_')[2])\n",
    "    videos['frame'] = videos['video_frame'].apply(lambda x: x.split('_')[-1])\n",
    "    videos['xc'] = (videos['left'] + videos['width']/2).astype(int).values\n",
    "    videos['yc'] = (videos['top'] + videos['height']/2).astype(int).values\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_field(xc, yc, player, r = 10, width = 3, col = [(27, 3, 163), (255, 7, 58)], crop = None, box = True):\n",
    "    field = Image.open('data/field.png')\n",
    "\n",
    "    w, h = field.size\n",
    "    zero = (68,68)\n",
    "    fs = (2424,1100)\n",
    "    draw = ImageDraw.Draw(field)\n",
    "    xc, yc = xc*fs[0]/120 + zero[0], (1 - yc/53.3)*fs[1] + zero[1]\n",
    "    for x, y, p in zip(xc, yc, player):\n",
    "        c = col[0] if p[0] == 'H' else col[1]\n",
    "        draw.ellipse((x-r, y-r, x+r, y+r), fill=c, width=width, outline = 'black')\n",
    "    if isinstance(crop, float):\n",
    "        if box:\n",
    "            cp = [xc.min() - crop*w, yc.min() - crop*h, xc.max() + crop*w, yc.max() + crop*h]\n",
    "        else:\n",
    "            cp = [xc.min() - crop*w, 0, xc.max() + crop*2*w, h]\n",
    "        field = field.crop(cp)\n",
    "        \n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df = pd.read_csv('data/train_player_tracking.csv')\n",
    "tracking_df = add_track_features(tracking_df)\n",
    "x, y, player = tracking_df.query(f\"game_play == '57583_000082' and est_frame == 10\")[['x', 'y', 'player']].values.transpose()\n",
    "annotate_field(x, y, player, r = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all together (tracking + camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class show_play_with_tracking():\n",
    "    \n",
    "    def __init__(self, video_df = None, track_df = None):\n",
    "        if video_df is None:\n",
    "            video_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')\n",
    "            self.video_df = add_video_features(video_df)\n",
    "        if track_df is None:\n",
    "            tracking_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_player_tracking.csv')\n",
    "            tracking_df = add_track_features(tracking_df)\n",
    "            self.tracking_df = tracking_df.query(\"est_frame > 0\")\n",
    "       \n",
    "    def __call__(self, game_play, frame, img_size = 800, video_folder = '../input/nfl-health-and-safety-helmet-assignment/train/'):\n",
    "        \n",
    "        camera = 'Sideline'\n",
    "        frame_side = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n",
    "        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n",
    "        frame_side = annotate_frame(frame_side, df.xc, df.yc, 10)\n",
    "\n",
    "        camera = 'Endzone'\n",
    "        frame_end = get_frame_from_video(frame, video_folder + game_play + '_' + camera + '.mp4')\n",
    "        df = self.video_df.query(f\"game_play == '{game_play}' and frame == '{frame}' and camera == '{camera}'\")\n",
    "        frame_end = annotate_frame(frame_end, df.xc, df.yc, 10)\n",
    "\n",
    "        frames = self.tracking_df['est_frame'].values\n",
    "        if frame not in frames:\n",
    "            index = np.absolute(frames-frame).argmin()\n",
    "            frame = frames[index]\n",
    "        df = self.tracking_df.query(f\"game_play == '{game_play}' and est_frame == {frame}\")\n",
    "        field = annotate_field(df.x, df.y, df.player, 10, crop = 0.01)\n",
    "\n",
    "        wf, hf = field.size\n",
    "        wc, hc = frame_side.size\n",
    "        field = field.resize((int(wf*2*hc/hf), 2*hc))\n",
    "        wf, hf = field.size\n",
    "\n",
    "        img = Image.new('RGB', (wf+wc+20, 2*hc+20))\n",
    "        img.paste(im=field, box=(5, 10))\n",
    "        img.paste(im=frame_side, box=(wf+15, 5))\n",
    "        img.paste(im=frame_end, box=(wf+15, hc+15))\n",
    "        img.thumbnail((img_size,img_size))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spwt = show_play_with_tracking()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
